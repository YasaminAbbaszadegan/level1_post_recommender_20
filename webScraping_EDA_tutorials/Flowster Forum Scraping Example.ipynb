{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping the eCommerce Sellers Forum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link: https://forum.flowster.app/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we open the above [link](https://forum.flowster.app) one of the things we see is the list of categories called Category, the number of topics per category and Latest posts.\n",
    "![First page](assets/1.png)\n",
    "What we are interested to get are:\n",
    "- The category urls for all the available categories\n",
    "- The topic urls for each category\n",
    "- The title, tags and comments or main post and replies\n",
    "- Etc (feel free to extract what you thing would be interesting to investigate for you)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using Firefox webdriver, selenium and beautiful soup to extract the data needed from this forum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get each catgory url"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First access the inspector and try to find out the HTML tag or identifier of these urls.\n",
    "As you can see when I click using the mouse inspector on the element containing Catgory, Topics and Latest I find them wrapped up in a div which class is `categories-and-latest ember-view` under which there is another div with the class name `column categories`.\n",
    "![Front page](assets/2.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the category url you can click on the category section itself:\n",
    "![More on first page](assets/3.png)\n",
    "You will find different HTML tags, what we are interested in is the `<a>`(hyperlink) tag that contains the `href` attribute that has the url of that category we just selected. We will then write the code to access that tag and get the value of its `href` attribute. \n",
    "![More on first page 2](assets/4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-a71dd96c898c>:6: DeprecationWarning: use setter for headless property instead of set_headless\n",
      "  opts.set_headless()\n"
     ]
    }
   ],
   "source": [
    "# Define the webdriver and provide the forum link\n",
    "from selenium.webdriver import Firefox\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "\n",
    "opts = Options()\n",
    "opts.set_headless()\n",
    "assert opts.headless # Operating in headless mode\n",
    "browser = Firefox(options=opts)\n",
    "browser.get('https://forum.flowster.app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to the a tag to get the content of its href\n",
    "categ_links = browser.find_elements_by_css_selector('.category > h3 > a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"139dbe67-ce87-dd4f-9da2-7d0c99a317e6\", element=\"228206b4-f575-2b4f-a674-ce0dfdd4a4ff\")>,\n",
       " <selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"139dbe67-ce87-dd4f-9da2-7d0c99a317e6\", element=\"e1d23a6f-84cf-684a-899a-84e72904e774\")>,\n",
       " <selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"139dbe67-ce87-dd4f-9da2-7d0c99a317e6\", element=\"20f00f40-305f-794c-bf44-fdc5e9c94e00\")>,\n",
       " <selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"139dbe67-ce87-dd4f-9da2-7d0c99a317e6\", element=\"feba649f-c15c-6048-9f55-e6f6e6058f8b\")>,\n",
       " <selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"139dbe67-ce87-dd4f-9da2-7d0c99a317e6\", element=\"683e202c-3335-c64e-8a7e-4975c369f7d3\")>,\n",
       " <selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"139dbe67-ce87-dd4f-9da2-7d0c99a317e6\", element=\"2353ed4b-8879-2045-9642-14b0b15c2fcd\")>,\n",
       " <selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"139dbe67-ce87-dd4f-9da2-7d0c99a317e6\", element=\"8e0a841a-5243-ed40-b883-1761cd0882df\")>,\n",
       " <selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"139dbe67-ce87-dd4f-9da2-7d0c99a317e6\", element=\"d5a2891f-a0d3-5c4f-b82a-069caec50b90\")>,\n",
       " <selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"139dbe67-ce87-dd4f-9da2-7d0c99a317e6\", element=\"2b123ff7-2188-0b46-8e99-17d409aa4631\")>,\n",
       " <selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"139dbe67-ce87-dd4f-9da2-7d0c99a317e6\", element=\"9a08b9ed-a0d6-9b45-a7b3-4ffe28111e99\")>,\n",
       " <selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"139dbe67-ce87-dd4f-9da2-7d0c99a317e6\", element=\"f502d2dc-5fc9-e94b-9da1-a2ba0fff8f72\")>,\n",
       " <selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"139dbe67-ce87-dd4f-9da2-7d0c99a317e6\", element=\"3cb53548-3a07-f24e-a0c0-c98173f9ccb7\")>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categ_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://forum.flowster.app/c/store-website-management/40'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the url of the first category : Store & Website Management \n",
    "categ_links[0].get_attribute('href')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the category topics urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Access the category by using its url.\n",
    "- Find the tag holding each topic url.\n",
    "- Extract the url and store it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the category by using its url\n",
    "import requests\n",
    "import time\n",
    "\n",
    "CATEG_URL = categ_links[0].get_attribute('href')\n",
    "browser.get(CATEG_URL)\n",
    "browser.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the tag holding each topic url**\n",
    "![Topics](assets/5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the tag holding each topic url\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(browser.page_source, 'html.parser') # Get the current HTML page content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate directly to the tag holding the url\n",
    "storeWebM_topics_links = soup.find_all('a', class_='title raw-link raw-topic-link') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"title raw-link raw-topic-link\" data-topic-id=\"58\" href=\"/t/about-the-store-website-management-category/58\">About the Store &amp; Website Management category</a>,\n",
       " <a class=\"title raw-link raw-topic-link\" data-topic-id=\"1545\" href=\"/t/securing-long-term-partnerships/1545\">Securing long term partnerships</a>,\n",
       " <a class=\"title raw-link raw-topic-link\" data-topic-id=\"1470\" href=\"/t/amazon-free-products/1470\">Amazon Free Products</a>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storeWebM_topics_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(storeWebM_topics_links) # we have 3 topics available in the Store & Website Management category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/t/about-the-store-website-management-category/58'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the 1st topic url\n",
    "storeWebM_topics_links[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the base url to form a full accessible url\n",
    "storeWebM_topic_urls = []\n",
    "BASE_URL = 'https://forum.flowster.app'\n",
    "for topic_link in storeWebM_topics_links:\n",
    "    storeWebM_topic_urls.append(BASE_URL + topic_link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://forum.flowster.app/t/about-the-store-website-management-category/58',\n",
       " 'https://forum.flowster.app/t/securing-long-term-partnerships/1545',\n",
       " 'https://forum.flowster.app/t/amazon-free-products/1470']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storeWebM_topic_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the topic post, replies and other info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note is that there is a difference between the class of the div holding the main post and the one holding the replies.\n",
    "- **Main post**  \n",
    "\n",
    "![Main post](assets/6.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Replies**  \n",
    "\n",
    "![Replies](assets/7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is why we will be iterating over the two classes to get the main post and the replies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the 2nd topic url\n",
    "\n",
    "SECOND_TOPIC_URL = storeWebM_topic_urls[1]\n",
    "browser.get(SECOND_TOPIC_URL)\n",
    "browser.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the HTML content of the current page\n",
    "secondTopic_soup = BeautifulSoup(browser.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get all the posts HTML**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Posts](assets/8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the posts HTML\n",
    "postStream = secondTopic_soup.find('div', class_='post-stream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the HTML for both the main and replies posts\n",
    "postsDivs = postStream.find_all('div', {'class': ['topic-post clearfix topic-owner regular', 'topic-post clearfix regular']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the main post text and the replies posts text\n",
    "comments = []\n",
    "for i in range(len(postsDivs)):\n",
    "    comment = postsDivs[i].find('div', class_='cooked').text\n",
    "    comments.append(comment)\n",
    "\n",
    "leading_comment = comments[0]\n",
    "if len(comments) == 1:\n",
    "    other_comments = []\n",
    "else:\n",
    "    other_comments = comments[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, I just closed a deal to manage a quite large brand account on Amazon, my main concern now is that this partnership may only last 1-2 years and once the account has grown to higher levels they would just manage it by themselves. What methods, tips and tricks you can suggest to protect this deal and make sure they will stick with my company managing their account for long term? Essentially how can I make them dependent on me so it will be very hard for them to let go our partnership?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leading_comment # main post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brand management is going to have partner turnover.  There will always be high expectations and, even if you raise sales 20%, they’ll want a 30% increase the next quarter.  I think one good tip is to set reasonable expectations.  Let them know all the activities you will undertake and don’t over-promise a sales increase.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_comments # replies posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract title, tags, number of views, likes and replies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dec 5, 2020 5:49 pm'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "created = postStream.find('li', class_=\"created-at\")\n",
    "created_at = created.find('span', class_='relative-date')['title']\n",
    "created_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dec 7, 2020 3:02 pm'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_reply = postStream.find('li', class_=\"last-reply\")\n",
    "last_reply = last_reply.find('span', class_='relative-date')['title']\n",
    "last_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replies = postStream.find('li', class_=\"replies\")\n",
    "nbr_replies = replies.find('span', class_='number').text\n",
    "nbr_replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'30'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "views = postStream.find('li', class_=\"secondary views\")\n",
    "nbr_views = views.find('span', class_='number').text\n",
    "nbr_views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Scraper Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from selenium.webdriver import Firefox\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "class WebScraper:\n",
    "    browser = None # Selenium webriver object\n",
    "    topic_dict = {} # Dictionary of all topics and their attributes\n",
    "    topic_df = pd.DataFrame(columns=[\n",
    "        'Topic Title',\n",
    "        'Category',\n",
    "        'Tags',\n",
    "        'Leading Post',\n",
    "        'Post Replies',\n",
    "        'Created_at',\n",
    "        'Likes',\n",
    "        'Views',\n",
    "        'Replies',\n",
    "    ])\n",
    "    \n",
    "    def __init__(self, webdriverPath):\n",
    "        # Set up the webdriver\n",
    "        opts = Options()\n",
    "        opts.set_headless()\n",
    "        assert opts.headless # Operating in headless mode\n",
    "        self.browser = Firefox(options=opts, executable_path=webdriverPath)\n",
    "        \n",
    "    def get_topic_title_details(self, topic_soup):\n",
    "        \"\"\"\n",
    "        Get topic title, category and tags\n",
    "        \"\"\"\n",
    "        topic_title = topic_soup.find('a', class_='fancy-title').text.strip()\n",
    "\n",
    "        title_wraper = topic_soup.find('div', class_='title-wrapper')\n",
    "\n",
    "        topic_tags = title_wraper.find_all('span', class_='category-name')\n",
    "        topic_tags = [tag.text for tag in topic_tags]\n",
    "        \n",
    "        try: \n",
    "            topic_category = topic_tags[0]\n",
    "        \n",
    "            if len(topic_tags) == 1:\n",
    "                topic_tags = []\n",
    "            else:\n",
    "                topic_tags = topic_tags[1:]\n",
    "        except:\n",
    "            topic_category = ''\n",
    "            topic_tags = ''\n",
    "            \n",
    "        return topic_title, topic_category, topic_tags\n",
    "        \n",
    "    def get_topic_comments(self, topic_soup):\n",
    "        \"\"\"\n",
    "        Get topic leading post and its replies.\n",
    "        \"\"\"\n",
    "        postStream = topic_soup.find('div', class_='post-stream')\n",
    "        postsDivs = postStream.find_all('div', {'class': ['topic-post clearfix topic-owner regular', 'topic-post clearfix regular']})\n",
    "\n",
    "        comments = []\n",
    "        for i in range(len(postsDivs)):\n",
    "            comment = postsDivs[i].find('div', class_='cooked').text\n",
    "            #postsDivs[i].find('div', class_='cooked').text.replace('\\n', ' ')\n",
    "            comments.append(comment)\n",
    "        try:\n",
    "            leading_comment = comments[0]\n",
    "            if len(comments) == 1:\n",
    "                other_comments = []\n",
    "            else:\n",
    "                other_comments = comments[1:]\n",
    "        except:\n",
    "            leading_comment, other_comments = [], []\n",
    "\n",
    "        return leading_comment, other_comments\n",
    "    \n",
    "    def get_topic_created_at(self, topic_soup):\n",
    "        \"\"\"\n",
    "        Get the topic creation date\n",
    "        \"\"\"\n",
    "        created = topic_soup.find('li', class_=\"created-at\")\n",
    "        \n",
    "        if created is None:\n",
    "            created_at = str(0)\n",
    "        else:\n",
    "            created_at = created.find('span', class_='relative-date')['title']\n",
    "    \n",
    "        return created_at\n",
    "\n",
    "    def get_topic_replies_nbr(self, topic_soup):\n",
    "        \"\"\"\n",
    "        Get the topic's nbr of replies\n",
    "        \"\"\"    \n",
    "        replies = topic_soup.find('li', class_=\"replies\")\n",
    "        \n",
    "        if replies == None:\n",
    "            nbr_replies = str(0)\n",
    "        else:\n",
    "            nbr_replies = replies.find('span', class_='number').text\n",
    "        \n",
    "        return nbr_replies\n",
    "\n",
    "    def get_topic_views_nbr(self, topic_soup):\n",
    "        \"\"\"\n",
    "        Get the topic's nbr of views\n",
    "        \"\"\" \n",
    "        views = topic_soup.find('li', class_=\"secondary views\")\n",
    "        \n",
    "        if views is None:\n",
    "            nbr_views = str(0)\n",
    "        else:\n",
    "            nbr_views = views.find('span', class_='number').text\n",
    "        \n",
    "        return nbr_views\n",
    "\n",
    "    def get_topic_likes_nbr(self, topic_soup):\n",
    "        \"\"\"\n",
    "        Get the topic's nbr of likes\n",
    "        \"\"\" \n",
    "        likes = topic_soup.find('li', class_=\"secondary likes\")\n",
    "        \n",
    "        if likes is None:\n",
    "            nbr_likes = str(0)\n",
    "        else:\n",
    "            nbr_likes = likes.find('span', class_='number').text\n",
    "        \n",
    "        return nbr_likes\n",
    "    \n",
    "    def runApp(self, BASE_URL, SITE_NAME):\n",
    "        \"\"\"\n",
    "        Run the scraping process\n",
    "        \"\"\"\n",
    "        # Open Firefox web client using Selenium and retrieve page source\n",
    "        self.browser.get(BASE_URL)\n",
    "        \n",
    "        # Get all the categories link \n",
    "        categ_links = self.browser.find_elements_by_css_selector('.category > h3 > a')\n",
    "        categ_urls = []\n",
    "        for link in categ_links:\n",
    "            categ_urls.append(link.get_attribute('href'))\n",
    "        \n",
    "        # Go over each category url\n",
    "        for categ_url in categ_urls:\n",
    "            # Access category webpage\n",
    "            self.browser.get(categ_url)\n",
    "            \n",
    "            # Load the entire webage by scrolling to the bottom\n",
    "            lastHeight = self.browser.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "            \n",
    "            while (True):\n",
    "                # Scroll to bottom of page\n",
    "                self.browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "                # Wait for new page segment to load\n",
    "                time.sleep(0.5)\n",
    "\n",
    "                # Calculate new scroll height and compare with last scroll height\n",
    "                newHeight = self.browser.execute_script(\"return document.body.scrollHeight\")\n",
    "                if newHeight == lastHeight:\n",
    "                    break\n",
    "                    \n",
    "                lastHeight = newHeight\n",
    "            \n",
    "            # Generate category soup\n",
    "            categoryHTML = self.browser.page_source\n",
    "            categ_topic_soup = BeautifulSoup(categoryHTML, 'html.parser')\n",
    "    \n",
    "            categ_topic_links = categ_topic_soup.find_all('a', class_='title raw-link raw-topic-link')\n",
    "    \n",
    "            # Get all the topic urls inside the current category\n",
    "            categ_topic_urls = []\n",
    "            for topic_link in categ_topic_links:\n",
    "                categ_topic_urls.append(BASE_URL + topic_link['href'])\n",
    "            \n",
    "            # Loop through all the topics in the current category\n",
    "            for categ_topic_url in categ_topic_urls:\n",
    "                # Get current topic_soup\n",
    "                self.browser.get(categ_topic_url)\n",
    "                topicHTML = self.browser.page_source\n",
    "                topic_soup = BeautifulSoup(topicHTML, 'html.parser')\n",
    "                \n",
    "                # Scrape all topic attributes of interest\n",
    "                topic_title, topic_category, topic_tags = self.get_topic_title_details(topic_soup)\n",
    "                leading_comment, other_comments = self.get_topic_comments(topic_soup)\n",
    "                created_at = self.get_topic_created_at(topic_soup)\n",
    "                nbr_replies = self.get_topic_replies_nbr(topic_soup)\n",
    "                nbr_views = self.get_topic_views_nbr(topic_soup)\n",
    "                nbr_likes = self.get_topic_likes_nbr(topic_soup)\n",
    "                \n",
    "                # Attribute dictionary for each topic in a category\n",
    "                attribute_dict = {\n",
    "                            'Topic Title': topic_title,\n",
    "                            'Category': topic_category,\n",
    "                            'Tags': topic_tags,\n",
    "                            'Leading Post': leading_comment,\n",
    "                            'Post Replies': other_comments,\n",
    "                            'Created_at': created_at,\n",
    "                            'Likes': nbr_likes,\n",
    "                            'Views': nbr_views,\n",
    "                            'Replies': nbr_replies}\n",
    "                \n",
    "                self.topic_dict[topic_title] = attribute_dict\n",
    "                self.topic_df = self.topic_df.append(attribute_dict, ignore_index=True)\n",
    "                \n",
    "                # TEST\n",
    "                print('Title :', topic_title)\n",
    "                print('Category :', topic_category)\n",
    "                print('URL :', categ_topic_url)\n",
    "                \n",
    "        # Get unique timestamp of the webscraping\n",
    "        timeStamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        \n",
    "        # Save data in JSON and CSV files and store in the save folder as this program\n",
    "        jsonFilename = SITE_NAME + '_SCRAPED_DATA_' + timeStamp + '.json'\n",
    "        csvFilename = SITE_NAME + '_SCRAPED_DATA_' + timeStamp + '.csv'\n",
    "        \n",
    "        jsonFileFullPath = os.path.join(os.path.dirname(os.path.realpath(__file__)), jsonFilename)\n",
    "        csvFileFullPath = os.path.join(os.path.dirname(os.path.realpath(__file__)), csvFilename)\n",
    "        \n",
    "        # Save scraped data  into json file\n",
    "        with open(jsonFileFullPath, 'w') as f:\n",
    "            json.dump(self.topic_dict, f)\n",
    "        \n",
    "        # Save dataframe into csv file\n",
    "        self.topic_df.to_csv(csvFileFullPath)\n",
    "        \n",
    "if __name__=='__main__':\n",
    "    # Local path to webdriver\n",
    "    webdriverPath = r'/usr/local/bin/geckodriver'\n",
    "    \n",
    "    # Forum to scrape URL    \n",
    "    BASE_URL = 'https://forum.flowster.app'\n",
    "    \n",
    "    # Name of the forum\n",
    "    SITE_NAME = 'FLOWSTER'\n",
    "        \n",
    "    # WebScraping object\n",
    "    webScraper = WebScraper(webdriverPath)\n",
    "    \n",
    "    # Run the webscraper and save scraped data\n",
    "    webScraper.runApp(BASE_URL, SITE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Explore the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('FLOWSTER_SCRAPED_DATA20201212224954.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Topic Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Leading Post</th>\n",
       "      <th>Post Replies</th>\n",
       "      <th>Created_at</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Views</th>\n",
       "      <th>Replies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>About the Store &amp; Website Management category</td>\n",
       "      <td>Store &amp; Website Management</td>\n",
       "      <td>[]</td>\n",
       "      <td>Have questions about Store &amp; Website Managemen...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Securing long term partnerships</td>\n",
       "      <td>Store &amp; Website Management</td>\n",
       "      <td>[]</td>\n",
       "      <td>Hello, I just closed a deal to manage a quite ...</td>\n",
       "      <td>['Brand management is going to have partner tu...</td>\n",
       "      <td>Dec 5, 2020 5:49 pm</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Amazon Free Products</td>\n",
       "      <td>Store &amp; Website Management</td>\n",
       "      <td>[]</td>\n",
       "      <td>Hello,\\nI need some buyers for my products in ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>About the Product Sourcing Category</td>\n",
       "      <td>Product Sourcing</td>\n",
       "      <td>[]</td>\n",
       "      <td>Have questions about sourcing products? This i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Virtual Assistant sending Emails Hubspot</td>\n",
       "      <td>Product Sourcing</td>\n",
       "      <td>[]</td>\n",
       "      <td>Hello Bright Ideas Tribe,\\nI would like to giv...</td>\n",
       "      <td>['\\n\\n\\nknowledge.hubspot.com 1\\n\\n\\n\\nCreate ...</td>\n",
       "      <td>Nov 18, 2020 9:12 pm</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                    Topic Title  \\\n",
       "0           0  About the Store & Website Management category   \n",
       "1           1                Securing long term partnerships   \n",
       "2           2                           Amazon Free Products   \n",
       "3           3            About the Product Sourcing Category   \n",
       "4           4       Virtual Assistant sending Emails Hubspot   \n",
       "\n",
       "                     Category Tags  \\\n",
       "0  Store & Website Management   []   \n",
       "1  Store & Website Management   []   \n",
       "2  Store & Website Management   []   \n",
       "3            Product Sourcing   []   \n",
       "4            Product Sourcing   []   \n",
       "\n",
       "                                        Leading Post  \\\n",
       "0  Have questions about Store & Website Managemen...   \n",
       "1  Hello, I just closed a deal to manage a quite ...   \n",
       "2  Hello,\\nI need some buyers for my products in ...   \n",
       "3  Have questions about sourcing products? This i...   \n",
       "4  Hello Bright Ideas Tribe,\\nI would like to giv...   \n",
       "\n",
       "                                        Post Replies            Created_at  \\\n",
       "0                                                 []                     0   \n",
       "1  ['Brand management is going to have partner tu...   Dec 5, 2020 5:49 pm   \n",
       "2                                                 []                     0   \n",
       "3                                                 []                     0   \n",
       "4  ['\\n\\n\\nknowledge.hubspot.com 1\\n\\n\\n\\nCreate ...  Nov 18, 2020 9:12 pm   \n",
       "\n",
       "   Likes  Views  Replies  \n",
       "0      0      0        0  \n",
       "1      0     19        1  \n",
       "2      0      0        0  \n",
       "3      0      0        0  \n",
       "4      0     81        5  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 278 entries, 0 to 277\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Unnamed: 0    278 non-null    int64 \n",
      " 1   Topic Title   278 non-null    object\n",
      " 2   Category      278 non-null    object\n",
      " 3   Tags          278 non-null    object\n",
      " 4   Leading Post  277 non-null    object\n",
      " 5   Post Replies  278 non-null    object\n",
      " 6   Created_at    278 non-null    object\n",
      " 7   Likes         278 non-null    int64 \n",
      " 8   Views         278 non-null    int64 \n",
      " 9   Replies       278 non-null    int64 \n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 21.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, I just closed a deal to manage a quite large brand account on Amazon, my main concern now is that this partnership may only last 1-2 years and once the account has grown to higher levels they would just manage it by themselves. What methods, tips and tricks you can suggest to protect this deal and make sure they will stick with my company managing their account for long term? Essentially how can I make them dependent on me so it will be very hard for them to let go our partnership?'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Leading Post'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_categ = data['Category'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Store & Website Management', 'Product Sourcing', 'Management',\n",
       "       'Amazon Specific', 'Fulfillment', 'Flowster-specific',\n",
       "       'eCommerce Marketplaces', 'Traffic Sources', 'Software & Tools',\n",
       "       'Financial Management', 'Human Resources', 'Misc Topics'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_categ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_categ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Resources for EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Check out these two resources and the ones in module for further info and methods:\n",
    "- https://www.analyticsvidhya.com/blog/2020/04/beginners-guide-exploratory-data-analysis-text-data/\n",
    "- `Processing Textual Data.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "232.727px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
